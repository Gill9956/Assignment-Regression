{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241e2028",
   "metadata": {},
   "source": [
    "## Assignment : Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9a0af",
   "metadata": {},
   "source": [
    "#### Question 1: What is Simple Linear Regression?\n",
    "\n",
    "#### Answer 1:\n",
    " SLR models the linear relationship between a single independent variable (X) and a dependent variable (Y) using the equation:\n",
    "  Y = mX + c + ε,\n",
    " where m is the slope, c is the intercept, and ε is the error term.\n",
    "\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ccf0dd",
   "metadata": {},
   "source": [
    "#### Question 2: What are the key assumptions of Simple Linear Regression?\n",
    "\n",
    "#### Answer 2:\n",
    " 1) Linearity: The relationship between X and Y is linear.\n",
    " 2) Independence: Observations are independent.\n",
    " 3) Homoscedasticity: Constant variance of residuals across values of X.\n",
    " 4) Normality: Residuals are normally distributed.\n",
    " 5) No multicollinearity (not applicable in SLR with only  one predictor).\n",
    "\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8ff90",
   "metadata": {},
   "source": [
    "#### Question 3: What does the coefficient m represent in Y = mX + c?\n",
    "\n",
    "#### ANswer 3:\n",
    " m is the slope — it represents the change in Y for a one-unit increase in X.\n",
    "\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f756b79",
   "metadata": {},
   "source": [
    "#### Question 4: What does the intercept c represent in Y = mX + c?\n",
    "\n",
    "#### Answer 4: \n",
    " c is the Y-intercept — the predicted value of Y when X = 0.\n",
    "\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe243be",
   "metadata": {},
   "source": [
    "#### Question 5: How do we calculate the slope m in Simple Linear Regression?\n",
    "\n",
    "#### Answer 5:\n",
    " m= ∑((Xi − Xmean)(Yi- Ymean))/∑(Xi -Xmean)^2\n",
    "\n",
    "----------------------------------------------------------\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe0201",
   "metadata": {},
   "source": [
    "#### Question 6: What is the purpose of the least squares method in SLR?\n",
    "\n",
    "#### Answer 6 :\n",
    " To minimize the sum of squared residuals (errors) between the observed and predicted Y values, resulting in the best-fitting line.\n",
    "\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b02e3",
   "metadata": {},
   "source": [
    "#### Question 7: How is the coefficient of determination (R²) interpreted in SLR?\n",
    "\n",
    "#### Answer 7:\n",
    " R² measures the proportion of variance in Y explained by X.\n",
    "\n",
    " R² = 1 → perfect fit\n",
    " R² = 0 → no linear relationship\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edbbb82",
   "metadata": {},
   "source": [
    "#### Question 8: What is Multiple Linear Regression?\n",
    "\n",
    "#### Answer 8:\n",
    " MLR models the relationship between two or more independent variables and a dependent variable:\n",
    "\n",
    " Y = b₀ + b₁X₁ + b₂X₂ + ... + bₙXₙ + ε\n",
    "\n",
    "--------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74058b",
   "metadata": {},
   "source": [
    "#### Question 9: Main difference between Simple and Multiple Linear Regression?\n",
    "\n",
    "#### Answer 9 : \n",
    " SLR uses one predictor variable.\n",
    "\n",
    " MLR uses multiple predictors to better capture complex relationships.\n",
    "\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98680b7b",
   "metadata": {},
   "source": [
    "#### Question 10: Key assumptions of Multiple Linear Regression:\n",
    "\n",
    "#### Answer 10:\n",
    " Linearity\n",
    "\n",
    " Independence\n",
    "\n",
    " Homoscedasticity\n",
    "\n",
    " Normality of residuals\n",
    "\n",
    " No multicollinearity among predictors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d447b",
   "metadata": {},
   "source": [
    "#### Question 11: What is heteroscedasticity, and how does it affect results?\n",
    "\n",
    "#### Answer 11:\n",
    " Heteroscedasticity means the residuals have non-constant variance.\n",
    " Leads to inefficient estimates and biased standard errors, making statistical tests unreliable.\n",
    "\n",
    "\n",
    "-----------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8e6f3",
   "metadata": {},
   "source": [
    "#### Question 12: How can you improve an MLR model with high multicollinearity?\n",
    "\n",
    "#### Answer 12:\n",
    " Remove or combine correlated predictors\n",
    "\n",
    " Use Principal Component Analysis (PCA)\n",
    "\n",
    " Apply Ridge or Lasso regression\n",
    "\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c077ca6",
   "metadata": {},
   "source": [
    "#### Question 13: Common techniques for transforming categorical variables in regression:\n",
    "\n",
    "#### Answer 13: \n",
    " One-hot encoding (creates binary columns)\n",
    " Label encoding (assigns numeric codes)\n",
    " Target/mean encoding (advanced method using target mean per category)\n",
    "\n",
    "----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b06ec",
   "metadata": {},
   "source": [
    "#### Question 14:Role of interaction terms in MLR:\n",
    "\n",
    "#### Answer 14:\n",
    " To model combined effects of variables. For example, if the effect of X₁ on Y depends on X₂, include X₁*X₂.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771daf9",
   "metadata": {},
   "source": [
    "#### Question 15: How can interpretation of intercept differ in SLR vs MLR?\n",
    "\n",
    "#### Answer 15:\n",
    " In SLR, intercept is Y when X = 0.\n",
    "\n",
    " In MLR, intercept is Y when all X variables = 0 — which may not be meaningful if Xs can't be zero.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7af7a",
   "metadata": {},
   "source": [
    "#### Questionm16:  What is the significance of the slope in regression?\n",
    "\n",
    "#### Answer 16:\n",
    " The slope quantifies the effect of an independent variable on the dependent variable.\n",
    "\n",
    "    A higher absolute value means a stronger effect.\n",
    "\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dbf821",
   "metadata": {},
   "source": [
    "#### Question 17: How does the intercept provide context?\n",
    "\n",
    "#### Answer 17: \n",
    " It gives a baseline value of Y when all independent variables are 0 — helps understand where the prediction line crosses the Y-axis.\n",
    "\n",
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cff12",
   "metadata": {},
   "source": [
    "#### Question 18: Limitations of using R² as a sole performance measure:\n",
    "\n",
    "#### Answer 18:\n",
    " Doesn’t indicate if model is appropriate\n",
    " Can be artificially inflated by adding variables\n",
    " Doesn’t account for overfitting (use Adjusted R² for this)\n",
    "\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede3ed6",
   "metadata": {},
   "source": [
    "#### Question 19: How would you interpret a large standard error for a regression coefficient?\n",
    "\n",
    "#### Answer 19:\n",
    " It suggests the estimate of the coefficient is unstable and less reliable — could be due to multicollinearity or outliers.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3318cd5",
   "metadata": {},
   "source": [
    "#### Question 20: How can heteroscedasticity be identified in residual plots, and why is it important?\n",
    "\n",
    "#### Answer 20:\n",
    " Identification: Plot residuals vs. predicted values — if spread increases or forms a pattern, it's heteroscedastic.\n",
    "\n",
    " Importance: Violates model assumptions, leading to incorrect inferences (e.g., wrong p-values, CI).\n",
    "\n",
    "\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e114765",
   "metadata": {},
   "source": [
    "#### Question 21: What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    "\n",
    "#### Answer 21:\n",
    " This indicates that additional predictors may not be contributing meaningfully to the model.\n",
    "\n",
    " High R² suggests the model fits the training data well.\n",
    "\n",
    " Low Adjusted R² implies the added variables do not improve the model after accounting for complexity.\n",
    " \n",
    " Conclusion: Possible overfitting or inclusion of irrelevant variables.\n",
    "\n",
    "---------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e59dd",
   "metadata": {},
   "source": [
    "#### Question 22: Why is it important to scale variables in Multiple Linear Regression?\n",
    "\n",
    "#### Answer 22:\n",
    " Ensures each variable contributes equally to the model.\n",
    "\n",
    " Helps in interpreting coefficients, especially with regularization (like Ridge or Lasso).\n",
    "\n",
    " Prevents variables with larger magnitudes from dominating.\n",
    "     Especially important when:\n",
    "         Units differ (e.g., salary vs. age).\n",
    "         Using polynomial or interaction terms.\n",
    "         Applying techniques like PCA or regularization.\n",
    "\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45d0e5",
   "metadata": {},
   "source": [
    "#### Question 23:  What is polynomial regression?\n",
    "\n",
    "#### Answer 23:\n",
    " A regression technique where the relationship between the independent variable and the dependent variable is modeled as an nth-degree polynomial.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38afbba5",
   "metadata": {},
   "source": [
    "#### Question 24: How does polynomial regression differ from linear regression?\n",
    "\n",
    "#### Answer 24:\n",
    " Linear Regression fits a straight line: Y = b₀ + b₁X\n",
    " \n",
    " Polynomial Regression fits a curve: Y = b₀ + b₁X + b₂X² + ... + bₙXⁿ\n",
    "     Polynomial regression can model nonlinear patterns, linear regression cannot.\n",
    "\n",
    "-------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5c904",
   "metadata": {},
   "source": [
    "#### Question 25: When is polynomial regression used?\n",
    "\n",
    "#### Answer 26:\n",
    " When the relationship between X and Y is nonlinear.\n",
    " When residuals in a linear model show systematic patterns.\n",
    " In scenarios like growth curves, price elasticity, or seasonal trends.\n",
    "\n",
    "---------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e2404",
   "metadata": {},
   "source": [
    "#### Question 26: What is the general equation for polynomial regression?\n",
    "\n",
    "#### Answer 26:\n",
    " Y= b0 + b1X1 + b2X2 + b3X1^2 + b4X2^2..........+bnZ^n \n",
    "Where n is the degree of the polynomial.\n",
    "\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebee90d",
   "metadata": {},
   "source": [
    "#### Question 27:  Can polynomial regression be applied to multiple variables?\n",
    "\n",
    "#### Answer 27:\n",
    " Yes. This is called multivariate polynomial regression.\n",
    " It can include terms like:\n",
    " \n",
    " X₁², X₂²\n",
    "\n",
    " Interaction terms like X₁·X₂\n",
    " Y= b0 + b1X1 + b2X2 + b3X1^2 + b4X2^2 + b5X1X2..........\n",
    "\n",
    "\n",
    "--------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c7cfe",
   "metadata": {},
   "source": [
    "#### Question 28: What are the limitations of polynomial regression?\n",
    "\n",
    "#### Answer 28: \n",
    "\n",
    " Overfitting with high-degree polynomials\n",
    " Poor extrapolation outside the data range\n",
    " Multicollinearity due to power and interaction terms\n",
    " Less interpretable than linear models\n",
    " Can be computationally intensive with many variables or high degrees\n",
    "\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2744ac",
   "metadata": {},
   "source": [
    "#### Question 29: What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "\n",
    "#### Answer 30:\n",
    " Adjusted R²\n",
    " Cross-validation (K-fold)\n",
    " AIC/BIC (penalizes complexity)\n",
    " RMSE or MAE\n",
    "  These help balance fit vs. complexity.\n",
    "\n",
    "------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48dae8",
   "metadata": {},
   "source": [
    "#### Question 30: Why is visualization important in polynomial regression?\n",
    "\n",
    "#### Answer 30:\n",
    " Helps detect nonlinear patterns in data\n",
    " Useful for choosing appropriate polynomial degree\n",
    " Reveals overfitting or underfitting visually\n",
    " Aids interpretability and communication\n",
    "\n",
    "------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382e85e",
   "metadata": {},
   "source": [
    "#### Question 31: How is polynomial regression implemented in Python?\n",
    "\n",
    "\n",
    "#### Answer 31: \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Example: degree 3 polynomial\n",
    "model = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\n",
    "\n",
    "# X must be 2D (reshape if needed)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "\n",
    "-----------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
